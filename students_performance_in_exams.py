# -*- coding: utf-8 -*-
"""Students_Performance_in_Exams

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vLcFb74iMsRdtN6-l8yG4bogWcXWPggF

Students Performance in Exams
"""

# Se inicia con las importaciones de paquetes necesarios
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Leeremos el Dataset desde el archivo .csv desgargado con el link provisto en el email del challenge de Universiddad Siglo 21

df = pd.read_csv("StudentsPerformance.csv")

# Parte 1: Análisis y Preparación de Datos

## Análisis Exploratorio de Datos AED o EDA

# Visualizo el dataset
df

# Ver los nombres de las columnas:
df.columns

# Observar las métricas generales del dataset
df.describe()

df.info()

df.shape

# Luego de observar los tipos de valores de todas las columnas, deseamos ver aquellas columnas que tienen variables Categóricas es decir, nó numéricas, ya que más adelante requerirán un tratamiento diferente

categorical_cols = df.select_dtypes(include='object').columns

categorical_cols

# Dentro de las columnas con variables Categóricas, buscamos ver los valores únicos que toman dichas variables para cada columna
# De allí que realizamos un loop iterando dentro del listado de columnas categóricas y para cada columna observamos sus valores únicos o diferentes

for i in categorical_cols:
    print(df[i].unique())

# Pre-Procesamiento de Datos:

# Manejo de valores faltantes

df.isnull().sum()

# No hay valores faltantes ni nulos por lo que no hace falta mayor limpieza de datos

# Visualizar la cantidad de hombres y mujeres dentro de la columna de género gender
plt.figure(figsize=(6, 4))
sns.countplot(x='gender', data=df)
plt.title('Gender Distribution')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

# Busco ver la cantidad de estudiantes que completaron cursos preparatorios
count_test = df['test preparation course'].value_counts()
count_test

# Visualizar como Gráfico de torta
labels = df['test preparation course'].value_counts().index
plt.figure(figsize= (7,7))
plt.pie(count_test,labels=labels,autopct='%1.1f%%')
plt.legend(labels)
plt.show()

# Creo una nueva columna en el dataframe que sea el promedio de las puntuaciones en las 3 materias

df['average_score']=(df['math score']+df['reading score']+df['writing score'])/3

# Veo como queda el dataframe con la nueva columna
df.head()

# Exploramos la relación entre la nota promedio y la nota en matemáticas
sns.scatterplot(x=df['average_score'],y=df['math score'],hue=df['gender'])

# lo mismo para lectura
sns.scatterplot(x=df['average_score'],y=df['reading score'],hue=df['gender'])

# Crear Matríz de Correlación para ver la influencia mutua entre las variables numéricas

correlation_matrix = df.corr()

# Generate the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Mapa de calor de Correlación')
plt.show()

# Explorar las relaciones entre el promedio de notas y otras variables
# 1. Género
avg_score_by_gender = df.groupby('gender')['average_score'].mean()

# 2. Nivel de educación de los padres
avg_score_by_parent_education = df.groupby('parental level of education')['average_score'].mean().sort_values()

# 3. Curso de preparación para la prueba
avg_score_by_test_prep = df.groupby('test preparation course')['average_score'].mean()

# 4. Raza/etnicidad
avg_score_by_race = df.groupby('race/ethnicity')['average_score'].mean().sort_values()

# 5. Tipo de almuerzo
avg_score_by_lunch = df.groupby('lunch')['average_score'].mean()

# Imprimir los resultados
print("Promedio General por género:", avg_score_by_gender)
print("Promedio General por nivel de educación de los padres:", avg_score_by_parent_education)
print("Promedio General por curso de preparación para la prueba:", avg_score_by_test_prep)
print("Promedio General por raza/etnicidad:", avg_score_by_race)
print("Promedio General por tipo de almuerzo:", avg_score_by_lunch)

# Graficar estas relaciones

# Creo una función que grafique los promedios por cada categoría y luego la aplico en cada columna

def plot_avg_score_by_category(avg_score_series, title, xlabel, color, ylabel='Average Score'):
    plt.figure(figsize=(10, 6))
    avg_score_series.sort_values().plot(kind='bar', color=color, edgecolor='black')
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.xticks(rotation=45)
    plt.show()

# Generando Gráficos de barras por categorías
plot_avg_score_by_category(avg_score_by_gender, 'Promedio General por Género', 'Gender', 'blue')
plot_avg_score_by_category(avg_score_by_parent_education, 'Promedio General por Nivel de Educación de los padres', 'Parental Level of Education', 'green')
plot_avg_score_by_category(avg_score_by_test_prep, 'Promedio General por Curso de Preparación', 'Test Preparation Course', 'red')
plot_avg_score_by_category(avg_score_by_race, 'Promedio General por Raza/Etnia', 'Race/Ethnicity', 'purple')
plot_avg_score_by_category(avg_score_by_lunch, 'Promedio General por Tipo de Almuerzo', 'Lunch Type', 'orange')

# Algunas conclusiones:
"""
Género (Gender): Parece que las mujeres tienden a tener un promedio general más alto que los hombres.
Raza/Etnia (Race/Ethnicity): Hay algunas diferencias en los promedios generales entre los distintos grupos, aunque no son muy pronunciadas ni significativas.
Nivel Educativo de los Padres (Parental Level of Education): Los estudiantes cuyos padres tienen un grado de máster tienden a tener promedios generales más altos; y a su vez mientras mayor es el nivel de educación general de los padres, el promedio es mayor.
Tipo de Almuerzo (Lunch): Los estudiantes con almuerzo estándar tienden a tener un promedio general más alto.
Curso de Preparación para el Examen (Test Preparation Course): Los estudiantes que completaron un curso de preparación tienden a tener un promedio general más alto.
"""



# Feature Engineering
# Label Encoding de las columnas categoricas para no hacer 1-Hot Encoding y añadir más columnas al dataframe que tengan colinealidad entre ellas

# Creo diccionarios para mapear las columnas categóricas y convertirlas a numéricas
gender = {
    'male':1,
    'female':0
}

race = {
    'group A':0,
    'group B':1,
    'group C':2,
    'group D':3,
    'group E':4
}

# Reemplazo las columnas gender y race por sus mapeos en label encoding
df['gender']=df['gender'].map(gender)
df['race/ethnicity']=df['race/ethnicity'].map(race)

df.head()

# Hago el mismo tipo de mapeo y label encoding para el nivel de educacion de los padres
level = {
    "bachelor's degree":0,
    'some college':1,
    "master's degree":2,
    "associate's degree":3,
    "high school":4,
    "some high school":5
}

df['parental level of education']=df['parental level of education'].map(level)

df.head()

df = pd.get_dummies(df,drop_first=True)

""" La función pd.get_dummies() se utiliza para convertir variables categóricas en un formato que sea más fácil de proporcionar a modelos de machine learning. Esta función crea una nueva columna por cada valor único en la columna original y asigna un 1 o un 0 (dummy variables) para cada registro, dependiendo de si el registro tiene ese valor o no.

El parámetro drop_first=True se utiliza para evitar la multicolinealidad, que es un problema común en estadísticas cuando se tienen variables altamente correlacionadas. Al establecer drop_first=True, la primera columna "dummy" se eliminará, asegurando que solo se creen
�
−
1
n−1 columnas "dummy" para una columna original con
�
n categorías únicas. Esto es especialmente útil en modelos de regresión lineal y otros algoritmos que son sensibles a la multicolinealidad.

"""

df.head()

# Parte 2:Construcción de Modelo de Machine Learning:
# Modelo de regresión:
"""Vamos a buscar predecir el promedio general en función de el resto de ariables. Si bien al colocar las 3 notas, el modelo dará un resultado casi exacto con mucha facilidad, el hecho de no colocar alguna de las notas o ninguna de ellas, haría un modelo con un nivel de predicción muy pobre. Por ello lo haremos y luego corroboraremos que no tenga overfitting.
"""

# Separamos el conjunto de Variables Independients X que serán utilizadas como variables predictora de la variable Y que es la variable a predecir

# Dataframe x de variables independientes, todascexcepto el promedio
x = df.drop(columns='average_score').values

# Ver el dataframe de las variables predictoras
x

x[0]

# La columna o array de valores tipo target o variable dependiente
y = df['average_score'].values

# Ver array de valores dependientes
y

# División entre datos de Entrenamiento y de Testeo

from sklearn.model_selection import train_test_split

# Se realiza la división con un 75% de datos para train y 25% para test
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)

# Seleccionamos como modelo de Regresión para predecir el promedio de notas o average_score al modelo Random Forest de Regresión

from sklearn.ensemble import RandomForestRegressor

# Inicializamos el modelo
model=RandomForestRegressor()

# Entrenamos el modelo ajustandolo a los datos de entrenamiento
model.fit(x_train,y_train)

# Predicciones:
# Se pasa al modelo los datos separados para prueba que no vió en el entrenamiento y se predice el valor del average_score o promedio de notas

predictions = model.predict(x_test)

# Veamos las predicciones
predictions

# Evaluación del modelo:
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from math import sqrt

# Visualizar el valor de R2 que es una métrica de evaluación muy importante
r2_score(y_test,predictions)

""" Podría parecer un valor demasiado alto y el modelo podría estar sufriendo overfitting, pero en realidad el valor del promedio general es muy simple de predecir disponiendo de las 3 notas que componen el promedio para un modelo de regresión lineal. De todos modos luego haremos un análisis de Validación cruzada para asegurarnos de la veracidad del resultado"""

mse = mean_squared_error(y_test,predictions)

rmse = sqrt(mse)

rmse

""" Este valor de rmse implica que el error en el promedio calculado por alumno puede tener un error promedio de solo 0.7 puntos en 100. Por lo que la precisión es altísima."""

#y_test = np.array([70, 85, 78, 92, 88, 76, 84, 90])
# Predictions = np.array([68, 84, 80, 89, 87, 75, 82, 91])

plt.figure(figsize=(10, 8))
plt.scatter(y_test, predictions, c='blue', label='Predictions vs Actual')
plt.xlabel('Promedio General Real')
plt.ylabel('Promedio General Predicho por el modelo')

max_value = max(max(y_test), max(predictions))
min_value = min(min(y_test), min(predictions))
plt.plot([min_value, max_value], [min_value, max_value], 'r--', label='45-degree line')

# Add title and legend
plt.title('Predicciones de Modelo de Regresión Random Forest vs Valores reales')
plt.legend()

plt.show()

# Luego de analizar los resultados del modelo, se procede a realizar una verificación del modelo por medio de un Cross Validation

""" Validación Cruzada:"""

# Importing necessary libraries for K-Folds Cross-Validation
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import numpy as np


rf = RandomForestRegressor(n_estimators=100, random_state=42)

# Se realiza una validación cruzada con k pliegues en este caso elegimos k= 5 pliegues en todo el conjunto de datos x e y
cv_scores = cross_val_score(rf, x, y, cv=5, scoring='r2')

# Calculate the mean and standard deviation of the cross-validation scores
cv_mean = np.mean(cv_scores)
cv_std = np.std(cv_scores)

cv_mean, cv_std



"""CONCLUSION:
El modelo de regresión da un valor muy alto de r2 pero luego, la hacer una validación cruzada y obtener un valor igualmente alto y cercano a 1, esto implica que en todo el conjunto de datos el modelo se comporta excepcionalmente bien y no tiene overfitting; de lo cual que el modelo arroja resultados muy precisos por la simlicidad de su valor a predecir."""



# Guardar el modelo en formato pickle para ser reutilizado cuando se desee

import pickle
pickle.dump(model,open('students_model.pkl','wb'))

